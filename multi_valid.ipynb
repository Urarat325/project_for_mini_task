{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import glob\n",
    "import decimal\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading docs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "def read_file(path: str, encoding: str, is_lower=False):\n",
    "    list_of_paragraph = []\n",
    "    buffer = []\n",
    "    with open(path, encoding=encoding) as file:\n",
    "        regex = re.compile(\n",
    "            r'(((?<!Статья )(?<!^)(?<!(\\.|\\s))(?<!     )[а-яА-Я\\d]{2,})([\\.]{0,1}[\\]\\)\\\"]{0,2}[\\.\\;\\:]{1}(\\s|$)))',\n",
    "            flags=re.IGNORECASE)\n",
    "        text = file.read()\n",
    "\n",
    "        if is_lower:\n",
    "            text = text.lower()\n",
    "        offset = 0\n",
    "        buf = ''\n",
    "        for ind, value in enumerate(regex.split(text, maxsplit=0)):\n",
    "            if ind == 0 + offset:\n",
    "                buf = value\n",
    "            if ind == 1 + offset:\n",
    "                list_of_paragraph.append((buf + value).strip())\n",
    "                offset += 6\n",
    "\n",
    "        second_regex = re.compile(r'([^\\dгст][\\.\\;\\:](?=\\s|$))', flags=re.IGNORECASE)\n",
    "\n",
    "        for value1 in list_of_paragraph:\n",
    "            buf = ''\n",
    "            for value in second_regex.split(value1, maxsplit=0):\n",
    "                if value == '':\n",
    "                    continue\n",
    "\n",
    "                if len(value) > 2 and buf != '':\n",
    "                    buffer.append(buf.strip())\n",
    "                    buf = value\n",
    "                elif len(value) > 2:\n",
    "                    buf = value\n",
    "                elif len(value) <= 2:\n",
    "                    buffer.append((buf + value).strip())\n",
    "                    buf = ''\n",
    "    return buffer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting file paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "list_of_path = list(filter(lambda x: not '1ДИ' in str(x), glob.glob(\"docs/*/*.txt\")))\n",
    "\n",
    "list_of_instruction_paths = list(filter(lambda x: str(x).startswith('docs\\\\Список ДИ'), list_of_path))\n",
    "list_of_external_doc_paths = list(filter(lambda x: str(x).startswith('docs\\\\Список внешних'), list_of_path))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparation of sentences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "['примечания:',\n 'общие требования.',\n '* в соответствии с требованиями инструкций;',\n 'методические указания.',\n 'приложения:',\n 'приложение',\n '- руководящими документами',\n 'и доп., вступ.',\n 'в ред.',\n 'начальник',\n 'начальника',\n 'начальник смены',\n '* заместитель начальника',\n 'примечание:',\n 'примечание.',\n 'примечания:',\n 'замечание устранено, подпись.',\n '(подпись).',\n 'по мере необходимости:',\n '(в ред.',\n 'федеральный закон от № -фз (ред.',\n '- федеральный закон от n -фз.']"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words = []\n",
    "with open('./stop.txt', encoding='windows-1251') as file:\n",
    "    for text in file.readlines():\n",
    "        if text.endswith('\\n'):\n",
    "            bad_words.append(text[:-1])\n",
    "bad_words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def clean(text: str) -> str:\n",
    "    text = re.sub(r'(\\d+)(?:\\.)?', '', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def valid(text: str) -> bool:\n",
    "    def mini_valid(x: str):\n",
    "        list_of_specific_symbols = ['.', ',', ':', ';']\n",
    "        for sym in list_of_specific_symbols:\n",
    "            if sym in x:\n",
    "                return len([y for y in re.split(r'\\s', ' '.join(x.split(sym, maxsplit=0))) if len(y) > 1]) > 2\n",
    "        return True\n",
    "\n",
    "    flag: bool = len(list(filter(lambda x: len(str(x)) > 0 and mini_valid(x), re.split(r'\\s', text, maxsplit=0)))) > 2\n",
    "    return len(text) > 3 and flag and text.strip() not in bad_words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "'making i.t ?asdver years old. Richard McClintock'"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean('maki2.9ng i.t ?asd213ver 2000.123.34 years old. Richa6.1rd McCl8intock')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "'федеральный закон от № -фз (ред.'"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean('- федеральный закон от 22.12.2014 n 443-фз.')\n",
    "clean('федеральный закон от № -фз (ред.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "'- федеральный закон от n -фз.'"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean('- федеральный закон от 22.12.2014 n 443-фз.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "valid(clean('- федеральный закон от 22.12.2014 n 443-фз.\\n     '))\n",
    "list_of_external_docs = []\n",
    "list_of_instructions = []\n",
    "\n",
    "in_lower_case = True\n",
    "\n",
    "for path_to_doc in list_of_instruction_paths:\n",
    "    buf_list = read_file(path_to_doc, 'windows-1251', in_lower_case)\n",
    "    buf_list = [clean(x) for x in buf_list]\n",
    "    buf_list = [x for x in buf_list if valid(x)]\n",
    "    list_of_instructions.append(buf_list)\n",
    "\n",
    "for path_to_doc in list_of_external_doc_paths:\n",
    "    buf_list = read_file(path_to_doc, 'windows-1251', in_lower_case)\n",
    "    buf_list = [clean(x) for x in buf_list]\n",
    "    buf_list = [x for x in buf_list if valid(x)]\n",
    "    list_of_external_docs.append(buf_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing the embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "download_first_model = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "embed = None\n",
    "size = 512\n",
    "if download_first_model:\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "else:\n",
    "    size = 768\n",
    "    embed = SentenceTransformer('nq-distilbert-base-v1', device='cuda')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting embeddings from instructions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.7 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 64\n",
    "list_of_instruction_embeddings = []\n",
    "\n",
    "for doc in list_of_instructions:\n",
    "    buffer = np.empty((0, size), float)\n",
    "    for i in range(0, len(doc), BATCH_SIZE):\n",
    "        batch = doc[i:i + BATCH_SIZE]\n",
    "        if download_first_model:\n",
    "            buffer = np.concatenate((buffer, embed(batch)), axis=0)\n",
    "        else:\n",
    "            buffer = np.concatenate((buffer, embed.encode(batch)), axis=0)\n",
    "\n",
    "    list_of_instruction_embeddings.append(buffer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting embeddings from external docs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 3s\n",
      "Wall time: 52.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 64\n",
    "list_of_embeddings_of_external_docs = []\n",
    "\n",
    "for doc in list_of_external_docs:\n",
    "    buffer = np.empty((0, size), float)\n",
    "    for i in range(0, len(doc), BATCH_SIZE):\n",
    "        batch = doc[i:i + BATCH_SIZE]\n",
    "        if download_first_model:\n",
    "            buffer = np.concatenate((buffer, embed(batch)), axis=0)\n",
    "        else:\n",
    "            buffer = np.concatenate((buffer, embed.encode(batch)), axis=0)\n",
    "\n",
    "    list_of_embeddings_of_external_docs.append(buffer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Computing similarity matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "list_for_df = []\n",
    "\n",
    "for index, doc1 in enumerate(list_of_instruction_embeddings):\n",
    "    buffer = {\n",
    "        'instruction_filename': list_of_instruction_paths[index]\n",
    "    }\n",
    "    for ind, doc2 in enumerate(list_of_embeddings_of_external_docs):\n",
    "        buffer['external_doc_filename'] = list_of_external_doc_paths[ind]\n",
    "        if download_first_model:\n",
    "            similarity_matrix = np.inner(doc1, doc2)\n",
    "        else:\n",
    "            similarity_matrix = cosine_similarity(doc1, doc2)\n",
    "\n",
    "        for i, row in enumerate(similarity_matrix):\n",
    "            buffer['sentence_number_from_instruction'] = i\n",
    "            buffer['sentence_number_from_external_doc'] = int(np.argmax(row))\n",
    "            buffer['value'] = np.max(row)\n",
    "            buffer['text_of_instruction'] = list_of_instructions[index][i]\n",
    "            buffer['text_of_external_doc'] = list_of_external_docs[ind][int(np.argmax(row))]\n",
    "\n",
    "            list_for_df.append(buffer.copy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        'sentence_number_from_instruction',\n",
    "        'sentence_number_from_external_doc',\n",
    "        'value',\n",
    "        'text_of_instruction',\n",
    "        'instruction_filename',\n",
    "        'text_of_external_doc',\n",
    "        'external_doc_filename'\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 24s\n",
      "Wall time: 6min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in enumerate(list_for_df):\n",
    "    # new_df.loc[index] = [\n",
    "    #     row['sentence_number_from_instruction'],\n",
    "    #     row['sentence_number_from_external_doc'],\n",
    "    #     row['value'],\n",
    "    #     row['text_of_instruction'],\n",
    "    #     row['instruction_filename'],\n",
    "    #     row['text_of_external_doc'],\n",
    "    #     row['external_doc_filename'],\n",
    "    # ]\n",
    "    new_df = new_df.append({\n",
    "        'sentence_number_from_instruction': row['sentence_number_from_instruction'],\n",
    "        'sentence_number_from_external_doc': row['sentence_number_from_external_doc'],\n",
    "        'value': row['value'],\n",
    "        'text_of_instruction': row['text_of_instruction'],\n",
    "        'instruction_filename': row['instruction_filename'],\n",
    "        'text_of_external_doc': row['text_of_external_doc'],\n",
    "        'external_doc_filename': row['external_doc_filename'],\n",
    "    }, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл создан\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(\"embeddings.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    new_df.to_excel(writer, 'good', engine='xlsxwriter')\n",
    "    sheets_good = writer.sheets['good']\n",
    "    sheets_good.autofilter(0, 0, new_df.shape[0], new_df.shape[1])\n",
    "\n",
    "    print(\"Файл создан\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
